{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlr2AMSr3q/WUAQQy2eCPJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungjae6874/Deeplearning/blob/master/Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rR9Go1CsYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "c04641fd-e2bd-40e8-97bd-0c5809c77fe6"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#배치크기 * 채널* 높이 * 너비의 크기의 텐서를 선언 이름은 inputs\n",
        "inputs = torch.Tensor(1,1,28,28)\n",
        "print('텐서의 크기 : {}'.format(inputs.shape))\n",
        "\n",
        "# 첫번째 합성곱 층 1채널짜리 입력받아서 32채널 뽑아낸다. 커널 사이즈 = 3, 패딩은 1\n",
        "conv1 = nn.Conv2d(1,32,3,padding=1)\n",
        "print(conv1)\n",
        "\n",
        "#2번째 합성곱 층 구현 32채널 짜리를 1층의 합성곱 연산을 통해받은 결과를 입력 받아 64채널로 뽑아내고 커널은 3 패딩은 1\n",
        "conv2 = nn.Conv2d(32,64,kernel_size=3, padding=1)\n",
        "print(conv2)\n",
        "\n",
        "#맥스풀링층을 구현 -> 높이 너비는 절반이고 채널은 그대로 유지\n",
        "pool = nn.MaxPool2d(2) #정수를 하나만 넣으면 그 값으로 커널사이즈, 스트라이드 둘다 지정됨\n",
        "print(pool)\n",
        "\n",
        "#구현체를 연결해서 합성곱 + 맥스풀링으로 모델 만들기\n",
        "\n",
        "#합성곱 1단계에 inputs 즉 mnist 넣기\n",
        "out = conv1(inputs)\n",
        "print(\"첫번째 합성곱 층을 지난 후 결과 : \")\n",
        "print(out.shape)\n",
        "\n",
        "#맥스풀링층\n",
        "out = pool(out)\n",
        "print(\"첫번째 맥스 풀링층을 지난 후 결과 : \")\n",
        "print(out.shape)\n",
        "\n",
        "#다시 이제 두번째 합성곱\n",
        "out = conv2(out)\n",
        "print(\"두번째 합성곱 층을 지난 후 결과 : \")\n",
        "print(out.shape)\n",
        "\n",
        "#다시 풀링층\n",
        "out = pool(out)\n",
        "print(\"두번째 맥스풀링층을 지난 후 결과 : \")\n",
        "print(out.shape)\n",
        "\n",
        "#텐서 한줄로 펼치기 작업\n",
        "out.size(0) #0번째 차원은 배치사이즈라서 1차원\n",
        "out.size(1) #1번쨰 차원은 64\n",
        "\n",
        "#out을 첫번째 차원인 배치차원은 그대로 두고 나머지는 한줄벡터로 펼치는 수식\n",
        "out = out.view(out.size(0), -1)\n",
        "print(out.shape)\n",
        "\n",
        "#배치 차원1차원을 제외하고 모두 하나의 차원으로 통합되었다\n",
        "#이제 완전연결층을 통과시킨다.\n",
        "#출력층은 10개 뉴런 배치해서 10개 차원 텐서로 변환가정\n",
        "\n",
        "fc = nn.Linear(3136,10) #input차원 : 3136, output차원  :10\n",
        "out = fc(out)\n",
        "print(out.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K     |████████████████████████████████| 592.3MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.17.5)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-0.3.0.post4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Collecting torch==1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "텐서의 크기 : torch.Size([1, 1, 28, 28])\n",
            "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "첫번째 합성곱 층을 지난 후 결과 : \n",
            "torch.Size([1, 32, 28, 28])\n",
            "첫번째 맥스 풀링층을 지난 후 결과 : \n",
            "torch.Size([1, 32, 14, 14])\n",
            "두번째 합성곱 층을 지난 후 결과 : \n",
            "torch.Size([1, 64, 14, 14])\n",
            "두번째 맥스풀링층을 지난 후 결과 : \n",
            "torch.Size([1, 64, 7, 7])\n",
            "torch.Size([1, 3136])\n",
            "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}